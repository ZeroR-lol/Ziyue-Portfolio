{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score,recall_score, roc_auc_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../Dataset/jigsaw-toxic-comment-classification-challenge/train.csv')\n",
    "X_test = pd.read_csv('../../Dataset/jigsaw-toxic-comment-classification-challenge/test.csv')\n",
    "y_test = pd.read_csv('../../Dataset/jigsaw-toxic-comment-classification-challenge/test_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10.17% data has labels.\n",
      "9.58% of data has label as toxic.\n",
      "1.00% of data has label as severe toxic.\n",
      "5.29% of data has label as obscene.\n",
      "0.30% of data has label as threat.\n",
      "4.94% of data has label as insult.\n",
      "0.88% of data has label as identity hate.\n"
     ]
    }
   ],
   "source": [
    "print('There are %.2f%% data has labels.' %(sum(combine>0)/data.shape[0]*100))\n",
    "print('%.2f%% of data has label as toxic.' %(sum(data['toxic']==1)/data.shape[0]*100))\n",
    "print('%.2f%% of data has label as severe toxic.' %(sum(data['severe_toxic']==1)/data.shape[0]*100))\n",
    "print('%.2f%% of data has label as obscene.' %(sum(data['obscene']==1)/data.shape[0]*100))\n",
    "print('%.2f%% of data has label as threat.' %(sum(data['threat']==1)/data.shape[0]*100))\n",
    "print('%.2f%% of data has label as insult.' %(sum(data['insult']==1)/data.shape[0]*100))\n",
    "print('%.2f%% of data has label as identity hate.' %(sum(data['identity_hate']==1)/data.shape[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Classification Problem\n",
    "#### Start with one label, treat it as a binary classification problem to test some ideas\n",
    "1. try models with normal data\n",
    "2. try models with downsample data\n",
    "3. try models with upsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['comment_text']\n",
    "y_train = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineer\n",
    "- going to try tokenize, remove un-English words, then stem\n",
    "- go with tfidf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stem\n",
    "snowballStemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a function to combine 3 into 1\n",
    "def token_stem(text):\n",
    "    word = [w for sent in sent_tokenize(text) for w in word_tokenize(sent)]\n",
    "    filtered = [filt for filt in word if re.search('[A-Za-z]', filt)]\n",
    "    stemmed = [snowballStemmer.stem(word) for word in filtered]\n",
    "    \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with stopwords warnings\n",
    "stop_w_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_stop = [snowballStemmer.stem(word) for word in stop_w_list]\n",
    "preprocess_stop = preprocess_stop + [\"'d\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should not use lower case cuz toxic comment seems like having many upper case words\n",
    "# Toxic words seems combine into 2 together, so use bi-gram\n",
    "# Consider imbalanced labels, min_df should not be too small\n",
    "# toxic comment is not that comman so max_df should not be too large\n",
    "# toxic word should be so many. There are really just a few words can be used toxically!!!\n",
    "# max_features should not be too large (also avoid curse of dimenality)\n",
    "tfidf = TfidfVectorizer(max_df=0.7, max_features=5000, lowercase=False,\n",
    "                                 min_df=10, stop_words=preprocess_stop,\n",
    "                                 use_idf=True, tokenizer=token_stem,\n",
    "                                 ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dlml/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['r', 'v'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "tfidf_features = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "- logistic regression, SVM, and Multinomial NB\n",
    "- Try them with parameter tuning but no sampling method first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_report(classifier, param_grid, X, y):\n",
    "    gsc = GridSearchCV(estimator=classifier, param_grid=param_grid, \n",
    "                       scoring='f1', n_jobs=-1, cv=5, verbose=2)\n",
    "    gsc.fit(X, y)\n",
    "    \n",
    "    return [f1_score(y, gsc.best_estimator_.predict(X)),\n",
    "            recall_score(y, gsc.best_estimator_.predict(X)),\n",
    "           gsc.best_estimator_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param = {'penalty': ['l1', 'l2'],\n",
    "           'C': [0.01, 0.1, 1, 5],\n",
    "           'class_weight': [None, 'balanced']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   13.7s finished\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr_result = tune_and_report(LogisticRegression(random_state=100), lr_param, tfidf_features, y_train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_param = {'alpha': [1.0, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "nb_result = tune_and_report(MultinomialNB(), nb_param, tfidf_features, y_train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param = {'C': [0.01, 0.1, 1, 5],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'class_weight': [None, 'balaned']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   10.0s finished\n"
     ]
    }
   ],
   "source": [
    "svm_result = tune_and_report(LinearSVC(random_state=100), svm_param, tfidf_features, y_train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame([lr_result[:2], nb_result[:2], svm_result[:2]])\n",
    "result.index = ['Logistic Regression', 'Multinomial NB', 'SVC']\n",
    "result.columns = ['f1', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.784520</td>\n",
       "      <td>0.697855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>0.689611</td>\n",
       "      <td>0.562050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.783696</td>\n",
       "      <td>0.692690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           f1    recall\n",
       "Logistic Regression  0.784520  0.697855\n",
       "Multinomial NB       0.689611  0.562050\n",
       "SVC                  0.783696  0.692690"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression is winner.\n",
    "- Class weight are both None selected by grid search for Linear Regression and SVC: means normal balanced doesn't improve performance.\n",
    "- What about ensemble method? It may take longer to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param = {\"n_estimators\": [10, 50, 100, 200],\n",
    "             \"max_depth\": [2,4,8,15],\n",
    "             \"max_features\": ['auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  3.1min finished\n"
     ]
    }
   ],
   "source": [
    "rf_result = tune_and_report(RandomForestClassifier(random_state=100), rf_param, tfidf_features, y_train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.784520</td>\n",
       "      <td>0.697855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>0.689611</td>\n",
       "      <td>0.562050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.783696</td>\n",
       "      <td>0.692690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.170869</td>\n",
       "      <td>0.093501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           f1    recall\n",
       "Logistic Regression  0.784520  0.697855\n",
       "Multinomial NB       0.689611  0.562050\n",
       "SVC                  0.783696  0.692690\n",
       "rf                   0.170869  0.093501"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.append({'f1': rf_result[0], 'recall': rf_result[1]}, ignore_index=True)\n",
    "result.index = ['Logistic Regression', 'Multinomial NB', 'SVC', 'rf']\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try SMOTE oversampling method to see if we can improve our performance\n",
    "- Random Forest performs worse which makes sense because random forest is not good at nlp types of tasks (especially with subsample of features)\n",
    "- Let us try better sample method to see if performance can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.linspace(0.1, 0.90, 10)\n",
    "\n",
    "param_grid = {\"smote__sampling_strategy\": weights,\n",
    "             \"smote__k_neighbors\": [3,5,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_models = [lr_result[2], svm_result[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  4.2min finished\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  5.1min finished\n"
     ]
    }
   ],
   "source": [
    "holder = []\n",
    "model = []\n",
    "for m in potential_models:\n",
    "    os_model = make_pipeline(SMOTE(), m)\n",
    "\n",
    "    os_result = tune_and_report(os_model, param_grid, tfidf_features, y_train['toxic'])\n",
    "    holder.append(os_result[:2])\n",
    "    model.append(os_result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [lr_result[:2], nb_result[:2], svm_result[:2]]\n",
    "li.extend(holder)\n",
    "result = pd.DataFrame(li)\n",
    "result.index = ['Logistic Regression', 'Multinomial NB', 'SVC', 'Logistic Regression US', 'SVC US']\n",
    "result.columns = ['f1', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.784520</td>\n",
       "      <td>0.697855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>0.689611</td>\n",
       "      <td>0.562050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.783696</td>\n",
       "      <td>0.692690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression US</th>\n",
       "      <td>0.796291</td>\n",
       "      <td>0.757944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC US</th>\n",
       "      <td>0.798436</td>\n",
       "      <td>0.754479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              f1    recall\n",
       "Logistic Regression     0.784520  0.697855\n",
       "Multinomial NB          0.689611  0.562050\n",
       "SVC                     0.783696  0.692690\n",
       "Logistic Regression US  0.796291  0.757944\n",
       "SVC US                  0.798436  0.754479"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling Result\n",
    "- SMOTE upsamling method works\n",
    "- SVC performance is better than Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend it to multi-class classificaiton\n",
    "- use provided labels to evaluate models\n",
    "- need to eliminate -1 in provided labels to get actual labels\n",
    "- Documentation says they use average AUC_ROC so we will include AUC_ROC here\n",
    "- We need to param tunes for each labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
    "       'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
       "1  0000247867823ef7     -1            -1       -1      -1      -1   \n",
       "\n",
       "   identity_hate  \n",
       "0             -1  \n",
       "1             -1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y_test = y_test[y_test['toxic'] != -1]\n",
    "true_X_test = X_test[X_test['id'].isin(true_y_test['id'])]\n",
    "true_y_test_no_id = true_y_test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf_features = tfidf.transform(true_X_test['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Tune and Train Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_label(classifier, param_grid, X_train, y_train, X_test, y_test):\n",
    "    gsc = GridSearchCV(estimator=classifier, param_grid=param_grid, \n",
    "                       scoring='roc_auc', n_jobs=2, cv=5, verbose=2)\n",
    "    gsc.fit(X_train, y_train)\n",
    "    \n",
    "    return roc_auc_score(y_test, gsc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(SMOTE(random_state=100), LogisticRegression(random_state=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.3, 0.7, 0.9]##np.linspace(0.1, 0.90, 10)\n",
    "\n",
    "param_grid = {\"smote__sampling_strategy\": weights,\n",
    "             \"smote__k_neighbors\": [3,5,8],\n",
    "             \"logisticregression__C\": [0.01, 0.1, 1, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  4.9min finished\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "lr_auc_list = [train_one_label(pipe, param_grid, tfidf_features, y_train[label], test_tfidf_features, true_y_test[label]) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression average AUC for all labels are 0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression average AUC for all labels are %.2f\" %(np.array(lr_auc_list).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Tune and Train Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(SMOTE(random_state=100), LinearSVC(random_state=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"smote__sampling_strategy\": weights,\n",
    "             \"smote__k_neighbors\": [3,5,8],\n",
    "             \"linearsvc__C\": [0.01, 0.1, 1, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=2)]: Done 180 out of 180 | elapsed:  3.7min finished\n"
     ]
    }
   ],
   "source": [
    "svc_auc_list = \\\n",
    "    [train_one_label(pipe, param_grid, tfidf_features, y_train[label], test_tfidf_features, true_y_test[label]) for label in labels]    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier average AUC for all labels are 0.89\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Classifier average AUC for all labels are %.2f\" %(np.array(svc_auc_list).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC with SMOTE upsampling outperform Logistic Regression.\n",
    "- now let us try more complex models\n",
    "- use Feed Forward Neron Network and treat the problem as a multilablel problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate=0.01, activation='relu'):\n",
    "    \n",
    "    # Create an Adam optimizer with the given learning rate\n",
    "    opt = Adam(lr=learning_rate)\n",
    "\n",
    "    # Create your binary classification model  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(8000, input_shape=(5000,), activation=activation, kernel_initializer='truncated_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1000, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "    # Compile your model with your optimizer, loss, and metrics\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter tunings took so long with limited sources I have. Pause for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# params = {'activation': ['relu', 'tanh'], 'batch_size': [100, 500, 1000, 10000], \n",
    "#           'epochs': [20, 50, 100, 200], 'learning_rate': [0.1, 0.01, 0.001]}\n",
    "\n",
    "# # Create a randomize search cv object passing in the parameters to try\n",
    "# random_search = RandomizedSearchCV(model, param_distributions = params, cv = 3, \n",
    "#                                    n_iter=10, n_jobs=4, verbose=2, random_state=100)\n",
    "\n",
    "# random_search.fit(tfidf_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_metric = EarlyStopping(monitor='val_auc', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8000)              40008000  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8000)              32000     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              8001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 6006      \n",
      "=================================================================\n",
      "Total params: 48,051,006\n",
      "Trainable params: 48,033,006\n",
      "Non-trainable params: 18,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/100\n",
      "159571/159571 [==============================] - 274s 2ms/step - loss: 0.1021 - auc: 0.8977 - val_loss: 0.1014 - val_auc: 0.9450\n",
      "Epoch 2/100\n",
      "159571/159571 [==============================] - 272s 2ms/step - loss: 0.0464 - auc: 0.9546 - val_loss: 0.0717 - val_auc: 0.9619\n",
      "Epoch 3/100\n",
      "159571/159571 [==============================] - 272s 2ms/step - loss: 0.0348 - auc: 0.9673 - val_loss: 0.0915 - val_auc: 0.9702\n",
      "Epoch 4/100\n",
      "159571/159571 [==============================] - 1745s 11ms/step - loss: 0.0230 - auc: 0.9729 - val_loss: 0.1006 - val_auc: 0.9742\n",
      "Epoch 5/100\n",
      "159571/159571 [==============================] - 279s 2ms/step - loss: 0.0165 - auc: 0.9754 - val_loss: 0.1091 - val_auc: 0.9759\n",
      "Epoch 6/100\n",
      "159571/159571 [==============================] - 288s 2ms/step - loss: 0.0116 - auc: 0.9766 - val_loss: 0.1179 - val_auc: 0.9769\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tfidf_features, y_train, epochs=100, batch_size=500,validation_data=(test_tfidf_features, true_y_test_no_id),\n",
    "         callbacks=[monitor_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if using 2 layers MLN, we can achieve a test average AUC as 0.9764 which is significantly higher than both logistic regression and linear SVC\n",
    "- Let us try to submite the result to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_features = tfidf.transform(X_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_result = pd.DataFrame(model.predict_proba(submission_features), columns=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_result = pd.concat([X_test['id'],submit_result], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_result.to_csv('../../Dataset/jigsaw-toxic-comment-classification-challenge/submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Submission Result\n",
    "- public socre: 0.95522, private score: 0.95612\n",
    "### What we can do to improve?\n",
    "- Try tune parameters for MLN when I have more computing resources\n",
    "- Try RNN with LSTM models since RNN model suits language scenario better than MLN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
